{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grc_T6OHAjl0",
        "outputId": "384365a4-12a5-482f-e3e3-0c30af4b570e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROZ-s4w-txtG",
        "outputId": "cd71c783-a476-4752-f14e-2383f8f5a3aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset extracted to: /content/dataset\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_path = \"/content/drive/MyDrive/archive.zip\"  # Update with your actual file path\n",
        "extract_path = \"/content/dataset\"  # Target directory for extraction\n",
        "\n",
        "# Unzip the file\n",
        "os.system(f\"unzip -q {zip_path} -d {extract_path}\")\n",
        "print(f\"✅ Dataset extracted to: {extract_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5jlAgdCI20me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-030vwuRAw-h",
        "outputId": "0c167c63-d785-4d7c-c731-1e951ced27d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1479 images belonging to 30 classes.\n",
            "Found 356 images belonging to 30 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Training VGG-16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 624ms/step - accuracy: 0.1140 - loss: 3.3227 - val_accuracy: 0.3006 - val_loss: 2.9053\n",
            "Epoch 2/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 440ms/step - accuracy: 0.3018 - loss: 2.7948 - val_accuracy: 0.3539 - val_loss: 2.4180\n",
            "Epoch 3/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 407ms/step - accuracy: 0.4260 - loss: 2.2752 - val_accuracy: 0.5618 - val_loss: 1.9628\n",
            "Epoch 4/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 416ms/step - accuracy: 0.6403 - loss: 1.8265 - val_accuracy: 0.6770 - val_loss: 1.5980\n",
            "Epoch 5/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 404ms/step - accuracy: 0.7206 - loss: 1.4928 - val_accuracy: 0.7416 - val_loss: 1.3537\n",
            "Epoch 6/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 417ms/step - accuracy: 0.7906 - loss: 1.2271 - val_accuracy: 0.7444 - val_loss: 1.1531\n",
            "Epoch 7/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 408ms/step - accuracy: 0.7827 - loss: 1.0251 - val_accuracy: 0.7444 - val_loss: 1.0297\n",
            "Epoch 8/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.8422 - loss: 0.8390"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/content/dataset/Segmented Medicinal Leaf Images\"\n",
        "\n",
        "# Image settings\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Data Augmentation & Loading\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "# Function to create models\n",
        "def create_model(base_model):\n",
        "    base_model.trainable = False  # Freeze the convolutional base\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"VGG-16\": create_model(VGG16(weights='imagenet', include_top=False, input_shape=IMAGE_SIZE + (3,))),\n",
        "}\n",
        "\n",
        "# Training all models\n",
        "history_dict = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    history = model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
        "    model.save(f\"{name}_model.h5\")\n",
        "    history_dict[name] = history\n",
        "\n",
        "# Plot accuracy comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "for name, history in history_dict.items():\n",
        "    plt.plot(history.history['accuracy'], label=f'{name} Train')\n",
        "    plt.plot(history.history['val_accuracy'], label=f'{name} Val')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate models\n",
        "for name, model in models.items():\n",
        "    loss, accuracy = model.evaluate(val_generator)\n",
        "    print(f\"{name} - Accuracy: {accuracy * 100:.2f}% | Loss: {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5SBuCCYP3UY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U92DbPYGaQ3Q",
        "outputId": "0b2dba94-8950-45d3-d15c-0ac27bca76a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf # This line was already in your code\n",
        "from tensorflow.keras.layers import Dropout # Import Dropout explicitly\n",
        "from tensorflow.keras.applications import  VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RxTT65C33p_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAc8PA_VZ58p",
        "outputId": "c2a926c7-efdc-4e43-8ff3-e9470322c7ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ResNet-50': 'Non-Medicinal', 'VGG-16': 'Non-Medicinal', 'EfficientNet-B0': 'Non-Medicinal', 'MobileNetV3': 'Medicinal'}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "def build_model(base_model, model_name):\n",
        "    base_model.trainable = False  # Freeze layers initially\n",
        "\n",
        "    # Unfreeze last layers for fine-tuning\n",
        "    if model_name in [\"VGG-16\",]:\n",
        "        for layer in base_model.layers[-10:]:  # Unfreeze last 10 layers\n",
        "            layer.trainable = True\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    # Adjust learning rate based on model\n",
        "    lr = 1e-4 if model_name in [\"ResNet-50\", \"VGG-16\"] else 5e-5\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load pre-trained models\n",
        "vgg16_model = build_model(VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)), \"VGG-16\")\n",
        "\n",
        "# Compile models\n",
        "for model in [ vgg16_model]:\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "def preprocess_image(image_path, model_name):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # Apply correct preprocessing for each model\n",
        "\n",
        "    if model_name == \"VGG-16\":\n",
        "        img = vgg_preprocess(img)\n",
        "\n",
        "\n",
        "    return np.expand_dims(img, axis=0)\n",
        "\n",
        "\n",
        "def predict_medicinal_leaf(image_path, models):\n",
        "    predictions = {}\n",
        "    for name, model in models.items():\n",
        "        img = preprocess_image(image_path, name)\n",
        "        pred = model(img, training=False).numpy()[0][0]  # Ensure correct inference\n",
        "        predictions[name] = 'Medicinal' if pred > 0.5 else 'Non-Medicinal'\n",
        "    return predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "models = {\n",
        "    'VGG-16': vgg16_model,\n",
        "\n",
        "}\n",
        "\n",
        "# Load trained weights before prediction (replace with actual trained weights path)\n",
        "# for model_name, model in models.items():\n",
        "#     model.load_weights(f'./{model_name}_weights.h5')\n",
        "\n",
        "image_path = '/content/sample_data/neem.jpg'  # Replace with actual path\n",
        "predictions = predict_medicinal_leaf(image_path, models)\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import  VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Dataset Path\n",
        "dataset_path = \"/content/dataset/Segmented Medicinal Leaf Images\"\n",
        "\n",
        "# Image settings\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Data Augmentation & Loading\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Compute Class Weights\n",
        "class_labels = np.array(train_generator.classes)\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(class_labels), y=class_labels)\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}"
      ],
      "metadata": {
        "id": "fE3NsyaV0qyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model Preprocessing Functions\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "\n",
        "\n",
        "def preprocess_image(image_path, model_name):\n",
        "    \"\"\"Preprocess image according to the specific model's requirements.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    if model_name == \"VGG-16\":\n",
        "        img = vgg_preprocess(img)\n",
        "    return np.expand_dims(img, axis=0)\n",
        "\n",
        "\n",
        "# Model Creation\n",
        "def build_model(base_model, model_name):\n",
        "    \"\"\"Builds and compiles a model with fine-tuning.\"\"\"\n",
        "    base_model.trainable = False  # Initially freeze the model\n",
        "\n",
        "     # Unfreeze last 10 layers for fine-tuning\n",
        "    for layer in base_model.layers[-5:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    # Set learning rate per model\n",
        "    lr = 1e-4 if model_name in [\"VGG-16\"] else 5e-5\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Load Pretrained Models\n",
        "vgg16_model = build_model(VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)), \"VGG-16\")\n",
        "# Train Models\n",
        "models = {\n",
        "\n",
        "    'VGG-16': vgg16_model,\n",
        "}\n",
        "\n",
        "history_dict = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=5,\n",
        "        class_weight=class_weights_dict\n",
        "    )\n",
        "    model.save(f\"{name}_model.h5\")\n",
        "    history_dict[name] = history\n",
        "\n",
        "# Plot Accuracy Comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "for name, history in history_dict.items():\n",
        "    plt.plot(history.history['accuracy'], label=f'{name} Train')\n",
        "    plt.plot(history.history['val_accuracy'], label=f'{name} Val')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tqCVPR1W09QW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}